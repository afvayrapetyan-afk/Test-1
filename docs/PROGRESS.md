# –ü—Ä–æ–≥—Ä–µ—Å—Å –†–∞–∑—Ä–∞–±–æ—Ç–∫–∏ - AI Business Portfolio Manager

–û–±–Ω–æ–≤–ª–µ–Ω–æ: 2026-01-13

## ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

### 1. Database Layer (100%)

**Models (SQLAlchemy ORM):**
- ‚úÖ [Trend](backend/app/modules/trends/models.py) - –ú–æ–¥–µ–ª—å —Ç—Ä–µ–Ω–¥–æ–≤ —Å –ø–æ–ª—è–º–∏: title, description, source, category, tags, engagement_score, velocity, metadata
- ‚úÖ [Idea](backend/app/modules/ideas/models.py) - –ú–æ–¥–µ–ª—å –±–∏–∑–Ω–µ—Å-–∏–¥–µ–π —Å 6 scoring –º–µ—Ç—Ä–∏–∫–∞–º–∏ (market_size, competition, demand, monetization, feasibility, time_to_market)
- ‚úÖ [AgentExecution](backend/app/modules/agents/models.py) - –ú–æ–¥–µ–ª—å –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è AI-–∞–≥–µ–Ω—Ç–æ–≤ —Å tracking tokens/cost

**Schemas (Pydantic Validation):**
- ‚úÖ Trends: TrendCreate, TrendUpdate, TrendOut, TrendList, TrendStats
- ‚úÖ Ideas: IdeaCreate, IdeaUpdate, IdeaOut, IdeaDetailedOut, IdeaList, IdeaStats
- ‚úÖ Agents: AgentExecutionCreate, AgentExecutionUpdate, AgentExecutionOut, AgentExecutionDetailedOut, RunAgentRequest

**Repositories (Data Access Layer):**
- ‚úÖ [TrendRepository](backend/app/modules/trends/repository.py) - CRUD + search + stats + duplicate detection
- ‚úÖ [IdeaRepository](backend/app/modules/ideas/repository.py) - CRUD + filtering –ø–æ score/status + stats
- ‚úÖ [AgentExecutionRepository](backend/app/modules/agents/repository.py) - CRUD + tracking + stats

**Services (Business Logic):**
- ‚úÖ [TrendService](backend/app/modules/trends/service.py) - Orchestration + logging
- ‚úÖ [IdeaService](backend/app/modules/ideas/service.py) - Orchestration + detailed analysis conversion
- ‚úÖ [AgentExecutionService](backend/app/modules/agents/service.py) - Orchestration + monitoring

### 2. API Layer (100%)

**Routers (FastAPI Endpoints):**

‚úÖ **Trends Router** ([backend/app/modules/trends/router.py](backend/app/modules/trends/router.py:17-144)):
- `GET /` - –°–ø–∏—Å–æ–∫ —Ç—Ä–µ–Ω–¥–æ–≤ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π –∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
- `GET /{id}` - –î–µ—Ç–∞–ª–∏ —Ç—Ä–µ–Ω–¥–∞
- `POST /` - –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞ (—Å duplicate detection)
- `PUT /{id}` - –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞
- `DELETE /{id}` - –£–¥–∞–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞
- `GET /stats` - –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
- `POST /search` - Full-text –ø–æ–∏—Å–∫

‚úÖ **Ideas Router** ([backend/app/modules/ideas/router.py](backend/app/modules/ideas/router.py:25-155)):
- `GET /` - –°–ø–∏—Å–æ–∫ –∏–¥–µ–π —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ (min_score, status, trend_id)
- `GET /{id}` - –î–µ—Ç–∞–ª–∏ –∏–¥–µ–∏ —Å –ø–æ–ª–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
- `POST /` - –°–æ–∑–¥–∞–Ω–∏–µ –∏–¥–µ–∏
- `PUT /{id}` - –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–¥–µ–∏
- `DELETE /{id}` - –£–¥–∞–ª–µ–Ω–∏–µ –∏–¥–µ–∏
- `GET /stats` - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–¥–µ–π
- `POST /analyze` - Trigger –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤ (TODO: Celery integration)

‚úÖ **Agents Router** ([backend/app/modules/agents/router.py](backend/app/modules/agents/router.py:21-112)):
- `GET /status` - –°—Ç–∞—Ç—É—Å –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤
- `POST /run` - –ó–∞–ø—É—Å–∫ AI-–∞–≥–µ–Ω—Ç–∞ (–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω —Å runner)
- `GET /executions` - –ò—Å—Ç–æ—Ä–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–π
- `GET /executions/{id}` - –î–µ—Ç–∞–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

### 3. Data Scrapers (50%)

‚úÖ **Base Scraper** ([backend/app/scrapers/base_scraper.py](backend/app/scrapers/base_scraper.py:1-100)):
- –ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö scrapers
- Validation, text cleaning, tag extraction
- Error handling interface

‚úÖ **Reddit Scraper** ([backend/app/scrapers/reddit_scraper.py](backend/app/scrapers/reddit_scraper.py:1-300)):
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç PRAW (Python Reddit API Wrapper)
- Scraping: hot, top, new, rising posts
- Metrics: upvotes, comments, awards, engagement score
- Auto category detection (AI, SaaS, marketplace, etc.)
- Tag extraction –∏–∑ titles –∏ flairs
- Velocity calculation (upvotes per hour)
- **Setup**: –°–º. [REDDIT_SETUP.md](docs/REDDIT_SETUP.md)

‚è≥ **Google Trends Scraper** - TODO
‚è≥ **Twitter/X Scraper** - TODO
‚è≥ **Telegram Scraper** - TODO

### 4. AI Agents Infrastructure (100%)

‚úÖ **Base Agent** ([backend/app/agents/base_agent.py](backend/app/agents/base_agent.py:1-217)):
- –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å OpenAI API
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π tracking tokens –∏ cost
- Error handling –∏ retry logic
- Lifecycle management (create execution ‚Üí run ‚Üí update with results)

‚úÖ **TrendScoutAgent** ([backend/app/agents/trend_scout_agent.py](backend/app/agents/trend_scout_agent.py:1-250)):
- Discovers trends –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
- ‚úÖ **Reddit integration**: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç RedditScraper –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ scraping
- Fallback: LLM-generated trends –µ—Å–ª–∏ scraper –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏: Reddit (—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ), Google Trends (TODO)
- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: sources, subreddits, limit, sort, time_filter
- –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: trends_discovered, trends_stored, duplicates_filtered, breakdown_by_source

‚úÖ **IdeaAnalystAgent** ([backend/app/agents/idea_analyst_agent.py](backend/app/agents/idea_analyst_agent.py:1-237)):
- –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–µ–Ω–¥—ã –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –±–∏–∑–Ω–µ—Å-–∏–¥–µ–∏
- Scoring –ø–æ 6 –º–µ—Ç—Ä–∏–∫–∞–º (0-100 –∫–∞–∂–¥–∞—è)
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç GPT-4o –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
- –î–µ—Ç–∞–ª—å–Ω—ã–µ reasoning –∏ evidence –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–∏
- –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: trends_analyzed, ideas_generated, ideas_stored, avg_score, top_idea

‚úÖ **Agent Runner** ([backend/app/agents/runner.py](backend/app/agents/runner.py:1-66)):
- Wrapper –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–≥–µ–Ω—Ç–æ–≤
- Async execution
- –°–µ–π—á–∞—Å: —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π (–±–ª–æ–∫–∏—Ä—É—é—â–∏–π)
- TODO: Celery integration –¥–ª—è —Ñ–æ–Ω–æ–≤–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

### 4. Infrastructure & Configuration (100%)

‚úÖ **Database Configuration:**
- [database.py](backend/app/core/database.py:1-69) - SQLAlchemy engine, session factory, Base
- [init.sql](backend/db/init.sql) - PostgreSQL schema —Å indexes, views, triggers

‚úÖ **Environment Configuration:**
- [.env.example](backend/.env.example) - –í—Å–µ environment variables
- [config.py](backend/app/core/config.py) - Pydantic Settings —Å validation

‚úÖ **Docker Setup:**
- [docker-compose.yml](docker-compose.yml) - Full stack: PostgreSQL, Redis, Qdrant, FastAPI, Celery
- [Dockerfile](backend/Dockerfile) - Multi-stage build –¥–ª—è backend

‚úÖ **Dependencies:**
- [requirements.txt](backend/requirements.txt) - 40+ packages (FastAPI, SQLAlchemy, OpenAI, CrewAI, etc.)

---

## üîÑ –í –ü—Ä–æ—Ü–µ—Å—Å–µ / TODO

### Priority 1: Core Functionality

**Scrapers & Data Collection:**
- ‚è≥ Reddit scraper —Å PRAW
- ‚è≥ Google Trends —Å pytrends
- ‚è≥ Twitter/X scraper
- ‚è≥ Telegram channels scraper
- ‚è≥ VK communities scraper
- ‚è≥ Yandex Wordstat integration

**Task Queue:**
- ‚è≥ Celery configuration (celery.py, tasks/)
- ‚è≥ Celery Beat –¥–ª—è scheduled jobs (hourly scraping, daily clustering)
- ‚è≥ Redis queue setup —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏ (scraping, agents, analysis)

**Vector Search:**
- ‚è≥ Qdrant integration –¥–ª—è semantic search
- ‚è≥ Embedding generation service (OpenAI embeddings)
- ‚è≥ Clustering –∏ similarity search

### Priority 2: Advanced Features

**Additional Agents:**
- ‚è≥ DevAgent - code generation
- ‚è≥ MarketingAgent - marketing strategy
- ‚è≥ SalesAgent - sales automation

**Workflow Orchestration:**
- ‚è≥ Business lifecycle state machine
- ‚è≥ Temporal integration –¥–ª—è durable workflows
- ‚è≥ Checkpoint –∏ recovery system

**Authentication & Authorization:**
- ‚è≥ JWT tokens
- ‚è≥ User management
- ‚è≥ RBAC (Role-Based Access Control)

### Priority 3: Frontend & UX

**Frontend Dashboard:**
- ‚è≥ React 18 + TypeScript setup
- ‚è≥ Dashboard page —Å metrics
- ‚è≥ Trends page —Å cluster visualization
- ‚è≥ Ideas page —Å radar charts
- ‚è≥ Businesses page —Å workflow diagrams
- ‚è≥ Real-time updates (WebSocket)

**Monitoring & Observability:**
- ‚è≥ Prometheus metrics
- ‚è≥ Grafana dashboards
- ‚è≥ Structured logging (structlog)
- ‚è≥ Error tracking (Sentry)

---

## üéØ –ì–æ—Ç–æ–≤–æ –∫ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é

### –ú–æ–∂–Ω–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–µ–π—á–∞—Å:

1. **Database Operations:**
   - –°–æ–∑–¥–∞–Ω–∏–µ, —á—Ç–µ–Ω–∏–µ, –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ, —É–¥–∞–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤
   - –°–æ–∑–¥–∞–Ω–∏–µ –∏–¥–µ–π —Å scoring
   - Tracking agent executions

2. **API Endpoints:**
   - –í—Å–µ CRUD –æ–ø–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ FastAPI
   - Pagination, filtering, search
   - Stats –∏ aggregations

3. **AI Agents:**
   - –ó–∞–ø—É—Å–∫ TrendScoutAgent (‚úÖ Reddit scraping –∏–ª–∏ LLM fallback)
   - –ó–∞–ø—É—Å–∫ IdeaAnalystAgent (–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–µ–Ω–¥—ã, —Å–æ–∑–¥–∞–µ—Ç scored ideas)
   - Cost tracking –∏ error handling

4. **Data Scraping:**
   - ‚úÖ Reddit scraper —Å PRAW (—Ç—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫—É API keys)
   - –°–º. [REDDIT_SETUP.md](docs/REDDIT_SETUP.md) –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

### –ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å:

```bash
# 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
cd backend
pip install -r requirements.txt

# 2. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å .env
cp .env.example .env
# –î–æ–±–∞–≤–∏—Ç—å OPENAI_API_KEY –≤ .env

# 3. –ó–∞–ø—É—Å—Ç–∏—Ç—å —á–µ—Ä–µ–∑ Docker Compose
docker-compose up -d postgres redis qdrant

# 4. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ë–î
docker exec -i postgres psql -U postgres -d ai_business_manager < backend/db/init.sql

# 5. –ó–∞–ø—É—Å—Ç–∏—Ç—å backend
cd backend
uvicorn app.main:app --reload

# 6. –û—Ç–∫—Ä—ã—Ç—å Swagger UI
# http://localhost:8000/docs

# 7. (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ù–∞—Å—Ç—Ä–æ–∏—Ç—å Reddit API
# –°–º. docs/REDDIT_SETUP.md
# –î–æ–±–∞–≤–∏—Ç—å REDDIT_* credentials –≤ .env

# 8. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –∞–≥–µ–Ω—Ç–æ–≤
# POST /api/v1/agents/run
# {
#   "agent_type": "trend_scout",
#   "params": {
#     "sources": ["reddit"],
#     "subreddits": ["SideProject", "startups"],
#     "limit": 20,
#     "sort": "hot",
#     "time_filter": "week"
#   }
# }
# –ë–µ–∑ Reddit API - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π fallback –Ω–∞ LLM generation
```

---

## üìä –ú–µ—Ç—Ä–∏–∫–∏

**–ö–æ–¥:**
- Backend Files: ~25 Python —Ñ–∞–π–ª–æ–≤
- Lines of Code: ~4,000+ LOC
- Models: 3 (Trend, Idea, AgentExecution)
- API Endpoints: 20+
- AI Agents: 3 (Base, TrendScout, IdeaAnalyst)
- Scrapers: 2 (Base, Reddit)

**–ü–æ–∫—Ä—ã—Ç–∏–µ:**
- Database Layer: 100%
- API Layer: 100%
- AI Agents: 80% (–±–∞–∑–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å + Reddit scraper)
- Scrapers: 30% (Reddit –≥–æ—Ç–æ–≤, Google Trends/Twitter TODO)
- Testing: 0% (tests –Ω–µ –Ω–∞–ø–∏—Å–∞–Ω—ã)

**–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**
1. ‚úÖ ~~–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Reddit scraper —Å PRAW~~ **–ì–û–¢–û–í–û**
2. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Google Trends scraper —Å pytrends
3. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å Celery –¥–ª—è async execution
4. –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å Qdrant –¥–ª—è vector search
5. –ù–∞–ø–∏—Å–∞—Ç—å tests (unit + integration)
6. –ù–∞—á–∞—Ç—å frontend —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É

---

## üöÄ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
Backend
‚îú‚îÄ‚îÄ Models (SQLAlchemy ORM) ‚úÖ
‚îú‚îÄ‚îÄ Schemas (Pydantic) ‚úÖ
‚îú‚îÄ‚îÄ Repositories (Data Access) ‚úÖ
‚îú‚îÄ‚îÄ Services (Business Logic) ‚úÖ
‚îú‚îÄ‚îÄ Routers (API Endpoints) ‚úÖ
‚îú‚îÄ‚îÄ AI Agents ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ BaseAgent ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ TrendScoutAgent ‚úÖ
‚îÇ   ‚îî‚îÄ‚îÄ IdeaAnalystAgent ‚úÖ
‚îú‚îÄ‚îÄ Scrapers ‚úÖ (50%)
‚îÇ   ‚îú‚îÄ‚îÄ BaseScraper ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ RedditScraper ‚úÖ
‚îÇ   ‚îî‚îÄ‚îÄ GoogleTrendsScraper ‚è≥
‚îú‚îÄ‚îÄ Tasks (Celery) ‚è≥
‚îî‚îÄ‚îÄ Vector Search (Qdrant) ‚è≥

Frontend ‚è≥
‚îú‚îÄ‚îÄ Dashboard
‚îú‚îÄ‚îÄ Trends Visualization
‚îú‚îÄ‚îÄ Ideas Analysis
‚îî‚îÄ‚îÄ Business Workflows

Infrastructure
‚îú‚îÄ‚îÄ PostgreSQL ‚úÖ
‚îú‚îÄ‚îÄ Redis ‚úÖ
‚îú‚îÄ‚îÄ Qdrant ‚úÖ
‚îú‚îÄ‚îÄ Celery ‚è≥
‚îî‚îÄ‚îÄ Monitoring ‚è≥
```

**–õ–µ–≥–µ–Ω–¥–∞:**
- ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ
- ‚è≥ TODO / –í –ø—Ä–æ—Ü–µ—Å—Å–µ
